{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import NonLinearICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebA_dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.u_star = data.attr[torch.randperm(data.attr.shape[0])]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, (attr, identity)  = self.data[idx]\n",
    "        image = torch.tensor(np.array(image), dtype=torch.float32).moveaxis(-1, 0)\n",
    "        u = attr\n",
    "        u_star = self.u_star[idx]\n",
    "        return image, u, u_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = torchvision.datasets.CelebA(\"data/CelebA\", split=\"train\", target_type=[\"attr\", \"identity\"])\n",
    "valid = torchvision.datasets.CelebA(\"data/CelebA\", split=\"valid\", target_type=[\"attr\", \"identity\"])\n",
    "test = torchvision.datasets.CelebA(\"data/CelebA\", split=\"test\", target_type=[\"attr\", \"identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(CelebA_dataset(train), batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(CelebA_dataset(valid), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(CelebA_dataset(test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dimension = 25\n",
    "model = NonLinearICA(3, hidden_dimension, dropout=0.2, data_type='CelebA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=35\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "log_dir = \"logs/CelebA/\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "device=\"cuda:9\"\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb01df3bc9d4141863e27076704495c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training on epoch:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e2e077db8700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training on epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# choose random u or u_star -> labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cephfs/home/cherniavskii/GMML2021Project/.env_gmml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cephfs/home/cherniavskii/GMML2021Project/.env_gmml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cephfs/home/cherniavskii/GMML2021Project/.env_gmml/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cephfs/home/cherniavskii/GMML2021Project/.env_gmml/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a00113f9dddb>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cephfs/home/cherniavskii/GMML2021Project/.env_gmml/lib/python3.7/site-packages/torchvision/datasets/celeba.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"img_align_celeba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cephfs/home/cherniavskii/GMML2021Project/.env_gmml/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs), desc=\"Training on epoch\"):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        x, u, u_star = batch\n",
    "        labels = torch.randint(0, 2, size=(x.shape[0], 1), dtype=x.dtype) # choose random u or u_star -> labels\n",
    "        u = torch.where(labels.bool(), u, u_star) # get u or u_star depending on label\n",
    "        \n",
    "        x = x.to(device)\n",
    "        u = u.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = model(x, u)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = (torch.sigmoid(output) > 0.5).float()\n",
    "        correct = (pred == labels).float().sum()\n",
    "        writer.add_scalar(\"Train/loss\", loss.cpu().item(), len(train_dataloader)*epoch + i)\n",
    "        writer.add_scalar(\"Train/accuracy\", correct/output.shape[0], len(train_dataloader)*epoch + i)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            x, u, u_star = batch\n",
    "            labels = torch.randint(0, 2, size=(x.shape[0], 1), dtype=x.dtype) # choose random u or u_star -> labels\n",
    "            u = torch.where(labels.bool(), u, u_star) # get u or u_star depending on label\n",
    "\n",
    "            x = x.to(device)\n",
    "            u = u.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(x, u)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.cpu().item()\n",
    "            \n",
    "            pred = (torch.sigmoid(output) > 0.5).float()\n",
    "            val_correct += (pred == labels).float().sum()\n",
    "    writer.add_scalar(\"Test/loss\", val_loss / len(test_dataloader), epoch)\n",
    "    writer.add_scalar(\"Test/accuracy\", val_correct / (len(test_dataloader)*batch_size), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, log_dir + f\"/model_n{hidden_dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.u_star = data.targets[torch.randperm(len(data.targets))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, u  = self.data[idx]\n",
    "        u_star = self.u_star[idx]\n",
    "        image = torch.tensor(np.array(image), dtype=torch.float32).unsqueeze(0)\n",
    "        u = nn.functional.one_hot(torch.tensor(u), len(self.data.classes))\n",
    "        u_star = nn.functional.one_hot(u_star, len(self.data.classes))\n",
    "        return image, u, u_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST(\"data/MNIST\", download=True, train=True)\n",
    "test = torchvision.datasets.MNIST(\"data/MNIST\", download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dataloader = DataLoader(MNIST_dataset(train), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(MNIST_dataset(test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dimension = 12\n",
    "model = NonLinearICA(1, hidden_dimension, dropout=0.2, data_type='MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=25\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "log_dir = \"logs/MNIST/\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "device=\"cuda:9\"\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae91009ab4504c819483a75ce3e134ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training on epoch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs), desc=\"Training on epoch\"):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        x, u, u_star = batch\n",
    "        labels = torch.randint(0, 2, size=(x.shape[0], 1), dtype=x.dtype) # choose random u or u_star -> labels\n",
    "        u = torch.where(labels.bool(), u, u_star) # get u or u_star depending on label\n",
    "        \n",
    "        x = x.to(device)\n",
    "        u = u.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = model(x, u)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = (torch.sigmoid(output) > 0.5).float()\n",
    "        correct = (pred == labels).float().sum()\n",
    "        writer.add_scalar(\"Train/loss\", loss.cpu().item(), len(train_dataloader)*epoch + i)\n",
    "        writer.add_scalar(\"Train/accuracy\", correct/output.shape[0], len(train_dataloader)*epoch + i)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            x, u, u_star = batch\n",
    "            labels = torch.randint(0, 2, size=(x.shape[0], 1), dtype=x.dtype) # choose random u or u_star -> labels\n",
    "            u = torch.where(labels.bool(), u, u_star) # get u or u_star depending on label\n",
    "\n",
    "            x = x.to(device)\n",
    "            u = u.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(x, u)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.cpu().item()\n",
    "            \n",
    "            pred = (torch.sigmoid(output) > 0.5).float()\n",
    "            val_correct += (pred == labels).float().sum()\n",
    "    writer.add_scalar(\"Test/loss\", val_loss / len(test_dataloader), epoch)\n",
    "    writer.add_scalar(\"Test/accuracy\", val_correct / (len(test_dataloader)*batch_size), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, log_dir + f\"/model_n{hidden_dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/MNIST/\"\n",
    "hidden_dim = 12\n",
    "model = torch.load(\"logs/MNIST/\" + f\"model_n{hidden_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonLinearICA(\n",
       "  (h): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    (11): Linear(in_features=1568, out_features=256, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Dropout(p=0.2, inplace=False)\n",
       "    (14): Linear(in_features=256, out_features=12, bias=True)\n",
       "  )\n",
       "  (psi): ModuleList(\n",
       "    (0): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (10): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (11): PsiICA(\n",
       "      (m): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.25, inplace=False)\n",
       "        (2): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.25, inplace=False)\n",
       "        (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward_h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_i$ represent a single dimension (unmixed source, disentangled feature).\n",
    "\n",
    "The total model output:\n",
    "\n",
    "$$r(x, u) = \\sum\\limits_{i=1}^n \\psi_i(h_i(\\mathbf{x}), \\mathbf{u})$$\n",
    "\n",
    "The $\\mathbf{u}$ should be \"one-hot\" encoded.\n",
    "\n",
    "To **train** the model, use binary cross-entropy, check the quality (accuracy, loss) on the validation dataset.\n",
    "\n",
    "To **compare** the quality with InfoGAN, take correlations of values of $h_i$ with classes. Take the representation on the test dataset, look at the different values of $h_i$ within one class, try to find meaningful explanations.\n",
    "\n",
    "Compare the correlation between sources ($h_i$, features).\n",
    "\n",
    "So, we have the same weigths for $h_i$, and n outputs (Simple conv net).\n",
    "\n",
    "Then, for $\\phi_i$ we have $n$ different fully-connected networks, where we have the $\\mathbb{u}$ vector dimension + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7090, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model(x, u), torch.randint(0, 2, size=(x.shape[0], 1), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.env_gmml)",
   "language": "python",
   "name": ".env_gmml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
